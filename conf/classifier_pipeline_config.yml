environment_paras:
  gpu_no: 0
  gpu_memory_fraction: 0.1


task_paras:
  task_name: intent_classification
  corpus : corpus
  dataset_name : intent_classification
  data_subdir: gf_intent_classifier_data_20210729

data_preprocessing_paras:
  train_size : 0.8
  dev_size : 0.1
  random_state: 111
  label_count_threshold : 100


train_paras:
  epoch: 50
  train_batch_size: 32
  output_dir : output/gf_intent_classification_output
  export_dir : export_model
  optimizer_name: hf_adamw
  learning_rate : 1e-4
  num_warmup_epoch: 2
  weight_decay_rate: 0.01
  # 默认值 5e-5
  early_stopping_steps: 10000
  exports_to_keep: 10
  save_checkpoints_steps: 1000


train_mode:
  do_train: False
  do_eval: False
  train_and_evaluate : True
  do_predict : False
  do_export : False
  predict_with_pb: True

model_paras:
  model_name : HFAlbertClassifierModel
  multilabel_classifier: False
  max_seq_length: 128
  with_pool: False
  dropout_rate: 0.1
  if_use_crf: True
  bert_base_model : albert
  pretrained_model_dir : pretrained_model/albert_tiny_zh_google
  # vocab.txt是模型的词典
  vocab_filename: vocab.txt
  model_config_filename: albert_config.json




predict_paras:
  top_k: 1
  predict_top_k: 3
  p_threshold: 0.3