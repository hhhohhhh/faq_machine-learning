#coding=utf-8
[main]
gpu_no= 0
gpu_memory_fraction=0.3
[train]
task_name = intent_classification
corpus = corpus
dataset_name = intent_classification
data_subdir= gf_intent_classifier_data_20210729

output_dir = output/gf_intent_classification_output
export_dir = export_model

model_name = HFAlbertClassifierModel
pretrained_model_dir = pretrained_model/albert_tiny_zh_google

with_pool = False
dropout_rate = 0.1
bert_base_model = albert
multilabel_classifier= False
max_seq_length= 128
optimizer_name= hf_adamw
learning_rate = 1e-4
num_warmup_epoch= 2
weight_decay_rate=0.01
# 默认值 5e-5
epoch=50
train_batch_size= 32
early_stopping_steps=10000
exports_to_keep= 10
save_checkpoints_steps= 1000


if_use_crf= True


[data_preprocessing]
train_size = 0.8
dev_size = 0.1
random_state=111
label_count_threshold = 100

[mode]
do_train=False
do_eval=False
train_and_evaluate = True
do_predict = False
do_export = False
predict_with_pb= True



[predict]
top_k=1
predict_top_k=3
p_threshold=0.3

